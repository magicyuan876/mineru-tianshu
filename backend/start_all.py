"""
MinerU Tianshu - Unified Startup Script
å¤©æ¢ç»Ÿä¸€å¯åŠ¨è„šæœ¬

ä¸€é”®å¯åŠ¨æ‰€æœ‰æœåŠ¡ï¼šAPI Server + LitServe Workers + Task Scheduler
è‡ªåŠ¨æ£€æŸ¥å¹¶ä¸‹è½½ OCR æ¨¡å‹ï¼ˆDeepSeek OCRã€PaddleOCR-VLï¼‰
"""

import subprocess
import signal
import sys
import time
import os
from loguru import logger
from pathlib import Path
import argparse


class TianshuLauncher:
    """å¤©æ¢æœåŠ¡å¯åŠ¨å™¨"""

    def __init__(
        self,
        output_dir="/tmp/mineru_tianshu_output",
        api_port=8000,
        worker_port=9000,
        workers_per_device=1,
        devices="auto",
        accelerator="auto",
        enable_mcp=False,
        mcp_port=8001,
    ):
        self.output_dir = output_dir
        self.api_port = api_port
        self.worker_port = worker_port
        self.workers_per_device = workers_per_device
        self.devices = devices
        self.accelerator = accelerator
        self.enable_mcp = enable_mcp
        self.mcp_port = mcp_port
        self.processes = []

    def check_ocr_models(self):
        """æ£€æŸ¥å¹¶ä¸‹è½½æ‰€æœ‰ OCR æ¨¡å‹ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡å¯åŠ¨ï¼‰"""
        import threading

        # 1. æ£€æŸ¥ DeepSeek OCR æ¨¡å‹
        def check_deepseek():
            try:
                from deepseek_ocr import DeepSeekOCREngine

                logger.info("ğŸ” Checking DeepSeek OCR model...")

                # è·å–é¡¹ç›®æ ¹ç›®å½•
                project_root = Path(__file__).parent.parent
                cache_dir = project_root / "models" / "deepseek_ocr"

                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
                model_exists = False
                local_model_path = cache_dir / "deepseek-ai" / "DeepSeek-OCR"

                if local_model_path.exists():
                    required_files = [
                        "config.json",
                        "tokenizer.json",
                        "modeling_deepseekocr.py",
                        "model-00001-of-000001.safetensors",
                    ]
                    model_exists = all((local_model_path / f).exists() for f in required_files)

                    if model_exists:
                        logger.info(f"âœ… DeepSeek OCR model found at: {local_model_path}")
                    else:
                        missing = [f for f in required_files if not (local_model_path / f).exists()]
                        logger.warning(f"âš ï¸  DeepSeek OCR model incomplete, missing: {missing}")

                if not model_exists:
                    logger.info("ğŸ“¥ DeepSeek OCR model not found, starting download...")
                    logger.info(f"ğŸ“ Download location: {cache_dir}")
                    logger.info("â³ This may take a few minutes (5-10GB)...")
                    logger.info("ğŸ’¡ Tip: Model downloads in background")

                    try:
                        DeepSeekOCREngine(cache_dir=str(cache_dir), auto_download=True)
                        logger.info("âœ… DeepSeek OCR model download completed!")
                    except Exception as e:
                        logger.warning(f"âš ï¸  DeepSeek OCR model download failed: {e}")
                        logger.info("   Model will be downloaded on first use")

            except ImportError:
                logger.debug("DeepSeek OCR not installed, skipping model check")
            except Exception as e:
                logger.debug(f"DeepSeek model check skipped: {e}")

        # 2. æ£€æŸ¥ PaddleOCR-VL æ¨¡å‹
        def check_paddleocr_vl():
            try:
                from paddleocr_vl import PaddleOCRVLEngine

                logger.info("ğŸ” Checking PaddleOCR-VL...")
                logger.info("   Note: PaddleOCR-VL models are auto-managed by PaddleOCR")
                logger.info("   Cache location: ~/.paddleocr/models/")
                logger.info("   Model will be auto-downloaded on first use (~2GB)")

                # æ£€æŸ¥ home ç›®å½•çš„æ¨¡å‹ç¼“å­˜
                home_dir = Path.home()
                model_cache_dir = home_dir / ".paddleocr" / "models"

                if model_cache_dir.exists():
                    logger.info(f"âœ… PaddleOCR model cache found at: {model_cache_dir}")
                else:
                    logger.info("â„¹ï¸  PaddleOCR model cache not found, will be created on first use")

                # ç®€å•åˆå§‹åŒ–å¼•æ“ï¼ˆä¸è§¦å‘ä¸‹è½½ï¼‰
                try:
                    PaddleOCRVLEngine()
                    logger.info("âœ… PaddleOCR-VL engine initialized successfully")
                except Exception as e:
                    logger.warning(f"âš ï¸  PaddleOCR-VL initialization failed: {e}")
                    logger.info("   This is normal if GPU is not available or dependencies are missing")

            except ImportError:
                logger.debug("PaddleOCR-VL not installed, skipping check")
            except Exception as e:
                logger.debug(f"PaddleOCR-VL check skipped: {e}")

        # åœ¨åå°çº¿ç¨‹ä¸­å¹¶è¡Œä¸‹è½½ä¸¤ä¸ªæ¨¡å‹
        thread1 = threading.Thread(target=check_deepseek, daemon=True)
        thread2 = threading.Thread(target=check_paddleocr_vl, daemon=True)

        thread1.start()
        thread2.start()

    def start_services(self):
        """å¯åŠ¨æ‰€æœ‰æœåŠ¡"""
        logger.info("=" * 70)
        logger.info("ğŸš€ MinerU Tianshu - AI Data Preprocessing Platform")
        logger.info("=" * 70)
        logger.info("å¤©æ¢ - ä¼ä¸šçº§ AI æ•°æ®é¢„å¤„ç†å¹³å°")
        logger.info("æ”¯æŒæ–‡æ¡£ã€å›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®å¤„ç†")
        logger.info("")

        try:
            total_services = 4 if self.enable_mcp else 3

            # 1. å¯åŠ¨ API Server
            logger.info(f"ğŸ“¡ [1/{total_services}] Starting API Server...")
            env = os.environ.copy()
            env["API_PORT"] = str(self.api_port)
            api_proc = subprocess.Popen([sys.executable, "api_server.py"], cwd=Path(__file__).parent, env=env)
            self.processes.append(("API Server", api_proc))
            time.sleep(3)

            if api_proc.poll() is not None:
                logger.error("âŒ API Server failed to start!")
                return False

            logger.info(f"   âœ… API Server started (PID: {api_proc.pid})")
            logger.info(f"   ğŸ“– API Docs: http://localhost:{self.api_port}/docs")
            logger.info("")

            # 2. å¯åŠ¨ LitServe Worker Pool
            logger.info(f"âš™ï¸  [2/{total_services}] Starting LitServe Worker Pool...")
            worker_cmd = [
                sys.executable,
                "litserve_worker.py",
                "--output-dir",
                self.output_dir,
                "--accelerator",
                self.accelerator,
                "--workers-per-device",
                str(self.workers_per_device),
                "--port",
                str(self.worker_port),
                "--devices",
                str(self.devices) if isinstance(self.devices, str) else ",".join(map(str, self.devices)),
            ]

            worker_proc = subprocess.Popen(worker_cmd, cwd=Path(__file__).parent)
            self.processes.append(("LitServe Workers", worker_proc))
            time.sleep(5)

            if worker_proc.poll() is not None:
                logger.error("âŒ LitServe Workers failed to start!")
                return False

            logger.info(f"   âœ… LitServe Workers started (PID: {worker_proc.pid})")
            logger.info(f"   ğŸ”Œ Worker Port: {self.worker_port}")
            logger.info(f"   ğŸ‘· Workers per Device: {self.workers_per_device}")
            logger.info("")

            # 3. å¯åŠ¨ Task Scheduler
            logger.info(f"ğŸ”„ [3/{total_services}] Starting Task Scheduler...")
            scheduler_cmd = [
                sys.executable,
                "task_scheduler.py",
                "--litserve-url",
                f"http://localhost:{self.worker_port}/predict",
                "--wait-for-workers",
            ]

            scheduler_proc = subprocess.Popen(scheduler_cmd, cwd=Path(__file__).parent)
            self.processes.append(("Task Scheduler", scheduler_proc))
            time.sleep(3)

            if scheduler_proc.poll() is not None:
                logger.error("âŒ Task Scheduler failed to start!")
                return False

            logger.info(f"   âœ… Task Scheduler started (PID: {scheduler_proc.pid})")
            logger.info("")

            # 4. å¯åŠ¨ MCP Serverï¼ˆå¯é€‰ï¼‰
            if self.enable_mcp:
                logger.info(f"ğŸ”Œ [4/{total_services}] Starting MCP Server...")
                mcp_env = os.environ.copy()
                mcp_env["API_BASE_URL"] = f"http://localhost:{self.api_port}"
                mcp_env["MCP_PORT"] = str(self.mcp_port)
                mcp_env["MCP_HOST"] = "0.0.0.0"

                mcp_proc = subprocess.Popen([sys.executable, "mcp_server.py"], cwd=Path(__file__).parent, env=mcp_env)
                self.processes.append(("MCP Server", mcp_proc))
                time.sleep(3)

                if mcp_proc.poll() is not None:
                    logger.error("âŒ MCP Server failed to start!")
                    return False

                logger.info(f"   âœ… MCP Server started (PID: {mcp_proc.pid})")
                logger.info(f"   ğŸŒ MCP Endpoint: http://localhost:{self.mcp_port}/mcp")
                logger.info("")

            # å¯åŠ¨æˆåŠŸ
            logger.info("=" * 70)
            logger.info("âœ… All Services Started Successfully!")
            logger.info("=" * 70)
            logger.info("")
            logger.info("ğŸ“š Quick Start:")
            logger.info(f"   â€¢ API Documentation: http://localhost:{self.api_port}/docs")
            logger.info(f"   â€¢ Submit Task:       POST http://localhost:{self.api_port}/api/v1/tasks/submit")
            logger.info(f"   â€¢ Query Status:      GET  http://localhost:{self.api_port}/api/v1/tasks/{{task_id}}")
            logger.info(f"   â€¢ Queue Stats:       GET  http://localhost:{self.api_port}/api/v1/queue/stats")
            if self.enable_mcp:
                logger.info(f"   â€¢ MCP Endpoint:      http://localhost:{self.mcp_port}/mcp/sse")
            logger.info("")
            logger.info("ğŸ”§ Service Details:")
            for name, proc in self.processes:
                logger.info(f"   â€¢ {name:20s} PID: {proc.pid}")
            logger.info("")
            logger.info("âš ï¸  Press Ctrl+C to stop all services")
            logger.info("=" * 70)
            logger.info("")
            logger.info("ğŸ’– If you find this project helpful, please consider:")
            logger.info("   â­ Star us on GitHub: https://github.com/magicyuan876/mineru-tianshu")
            logger.info("   ğŸ› Report issues or contribute: https://github.com/magicyuan876/mineru-tianshu/issues")
            logger.info("")
            logger.info("=" * 70)
            logger.info("")

            # æ‰€æœ‰æœåŠ¡å¯åŠ¨å®Œæˆåï¼Œæ£€æŸ¥å¹¶ä¸‹è½½æ‰€æœ‰ OCR æ¨¡å‹
            self.check_ocr_models()

            return True

        except Exception as e:
            logger.error(f"âŒ Failed to start services: {e}")
            self.stop_services()
            return False

    def stop_services(self, signum=None, frame=None):
        """åœæ­¢æ‰€æœ‰æœåŠ¡"""
        logger.info("")
        logger.info("=" * 70)
        logger.info("â¹ï¸  Stopping All Services...")
        logger.info("=" * 70)

        for name, proc in self.processes:
            if proc.poll() is None:  # è¿›ç¨‹ä»åœ¨è¿è¡Œ
                logger.info(f"   Stopping {name} (PID: {proc.pid})...")
                proc.terminate()

        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹ç»“æŸ
        for name, proc in self.processes:
            try:
                proc.wait(timeout=10)
                logger.info(f"   âœ… {name} stopped")
            except subprocess.TimeoutExpired:
                logger.warning(f"   âš ï¸  {name} did not stop gracefully, forcing...")
                proc.kill()
                proc.wait()

        logger.info("=" * 70)
        logger.info("âœ… All Services Stopped")
        logger.info("=" * 70)
        sys.exit(0)

    def wait(self):
        """ç­‰å¾…æ‰€æœ‰æœåŠ¡"""
        try:
            while True:
                time.sleep(1)

                # æ£€æŸ¥è¿›ç¨‹çŠ¶æ€
                for name, proc in self.processes:
                    if proc.poll() is not None:
                        logger.error(f"âŒ {name} unexpectedly stopped!")
                        self.stop_services()
                        return

        except KeyboardInterrupt:
            self.stop_services()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="MinerU Tianshu - ç»Ÿä¸€å¯åŠ¨è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ä½¿ç”¨é»˜è®¤é…ç½®å¯åŠ¨ï¼ˆè‡ªåŠ¨æ£€æµ‹GPUï¼‰
  python start_all.py

  # ä½¿ç”¨CPUæ¨¡å¼
  python start_all.py --accelerator cpu

  # æŒ‡å®šè¾“å‡ºç›®å½•å’Œç«¯å£
  python start_all.py --output-dir /data/output --api-port 8080

  # æ¯ä¸ªGPUå¯åŠ¨2ä¸ªworker
  python start_all.py --accelerator cuda --workers-per-device 2

  # åªä½¿ç”¨æŒ‡å®šçš„GPU
  python start_all.py --accelerator cuda --devices 0,1

  # å¯ç”¨ MCP Server æ”¯æŒï¼ˆç”¨äº AI åŠ©æ‰‹è°ƒç”¨ï¼‰
  python start_all.py --enable-mcp --mcp-port 8001
        """,
    )

    parser.add_argument(
        "--output-dir",
        type=str,
        default="/tmp/mineru_tianshu_output",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: /tmp/mineru_tianshu_output)",
    )
    parser.add_argument("--api-port", type=int, default=8000, help="APIæœåŠ¡å™¨ç«¯å£ (é»˜è®¤: 8000)")
    parser.add_argument("--worker-port", type=int, default=9000, help="WorkeræœåŠ¡å™¨ç«¯å£ (é»˜è®¤: 9000)")
    parser.add_argument(
        "--accelerator",
        type=str,
        default="auto",
        choices=["auto", "cuda", "cpu", "mps"],
        help="åŠ é€Ÿå™¨ç±»å‹ (é»˜è®¤: autoï¼Œè‡ªåŠ¨æ£€æµ‹)",
    )
    parser.add_argument("--workers-per-device", type=int, default=1, help="æ¯ä¸ªGPUçš„workeræ•°é‡ (é»˜è®¤: 1)")
    parser.add_argument("--devices", type=str, default="auto", help="ä½¿ç”¨çš„GPUè®¾å¤‡ï¼Œé€—å·åˆ†éš” (é»˜è®¤: autoï¼Œä½¿ç”¨æ‰€æœ‰GPU)")
    parser.add_argument(
        "--enable-mcp", action="store_true", help="å¯ç”¨ MCP Serverï¼ˆæ”¯æŒ Model Context Protocol è¿œç¨‹è°ƒç”¨ï¼‰"
    )
    parser.add_argument("--mcp-port", type=int, default=8001, help="MCP Server ç«¯å£ (é»˜è®¤: 8001)")

    args = parser.parse_args()

    # å¤„ç† devices å‚æ•°
    devices = args.devices
    if devices != "auto":
        try:
            devices = [int(d) for d in devices.split(",")]
        except ValueError:
            logger.warning(f"Invalid devices format: {devices}, using 'auto'")
            devices = "auto"

    # åˆ›å»ºå¯åŠ¨å™¨
    launcher = TianshuLauncher(
        output_dir=args.output_dir,
        api_port=args.api_port,
        worker_port=args.worker_port,
        workers_per_device=args.workers_per_device,
        devices=devices,
        accelerator=args.accelerator,
        enable_mcp=args.enable_mcp,
        mcp_port=args.mcp_port,
    )

    # è®¾ç½®ä¿¡å·å¤„ç†
    signal.signal(signal.SIGINT, launcher.stop_services)
    signal.signal(signal.SIGTERM, launcher.stop_services)

    # å¯åŠ¨æœåŠ¡
    if launcher.start_services():
        launcher.wait()
    else:
        sys.exit(1)


if __name__ == "__main__":
    main()
