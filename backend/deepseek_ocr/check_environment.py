"""
ç¯å¢ƒæ£€æŸ¥è„šæœ¬
ç”¨äºè¯Šæ–­ DeepSeek OCR è¿è¡Œç¯å¢ƒæ˜¯å¦æ»¡è¶³è¦æ±‚
"""
import sys

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒé…ç½®"""
    print("=" * 80)
    print("ğŸ” DeepSeek OCR ç¯å¢ƒæ£€æŸ¥")
    print("=" * 80)
    print()
    
    issues = []
    warnings = []
    
    # 1. æ£€æŸ¥ Python ç‰ˆæœ¬
    print("ğŸ“Œ Python ç‰ˆæœ¬:")
    python_version = sys.version.split()[0]
    print(f"   {python_version}")
    if sys.version_info < (3, 8):
        issues.append("Python ç‰ˆæœ¬è¿‡ä½ï¼Œå»ºè®® >= 3.8")
    print()
    
    # 2. æ£€æŸ¥ PyTorch
    print("ğŸ“Œ æ£€æŸ¥ PyTorch:")
    try:
        import torch
        print(f"   âœ… PyTorch å·²å®‰è£…: {torch.__version__}")
    except ImportError:
        print("   âŒ PyTorch æœªå®‰è£…")
        issues.append("è¯·å®‰è£… PyTorch: pip install torch")
        return
    print()
    
    # 3. æ£€æŸ¥ CUDA
    print("ğŸ“Œ æ£€æŸ¥ CUDA:")
    if torch.cuda.is_available():
        print(f"   âœ… CUDA å¯ç”¨")
        print(f"   ç‰ˆæœ¬: {torch.version.cuda}")
        print(f"   è®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            device_name = torch.cuda.get_device_name(i)
            device_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"   GPU {i}: {device_name} ({device_memory:.1f} GB)")
            if device_memory < 8:
                warnings.append(f"GPU {i} æ˜¾å­˜ä¸è¶³ 8GBï¼Œå¯èƒ½å½±å“æ€§èƒ½")
    else:
        print("   âŒ CUDA ä¸å¯ç”¨")
        issues.append("CUDA ä¸å¯ç”¨ - DeepSeek OCR éœ€è¦ GPU æ”¯æŒ")
        
        # æä¾›è¯¦ç»†è¯Šæ–­
        print()
        print("   ğŸ“‹ å¯èƒ½çš„åŸå› :")
        print("      1. æ‚¨çš„ç”µè„‘æ²¡æœ‰ NVIDIA æ˜¾å¡")
        print("      2. æ²¡æœ‰å®‰è£… CUDA é©±åŠ¨ (è¿è¡Œ nvidia-smi æ£€æŸ¥)")
        print("      3. å®‰è£…çš„æ˜¯ CPU ç‰ˆæœ¬çš„ PyTorch")
        print()
        print("   ğŸ”§ è§£å†³æ–¹æ¡ˆ:")
        print("      # å¸è½½å½“å‰ç‰ˆæœ¬")
        print("      pip uninstall torch torchvision torchaudio")
        print()
        print("      # å®‰è£… CUDA 11.8 ç‰ˆæœ¬")
        print("      pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
        print()
        print("      # æˆ–è€…å®‰è£… CUDA 12.1 ç‰ˆæœ¬")
        print("      pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
    print()
    
    # 4. æ£€æŸ¥ä¾èµ–åŒ…
    print("ğŸ“Œ æ£€æŸ¥ä¾èµ–åŒ…:")
    required_packages = {
        'transformers': 'transformers',
        'Pillow': 'PIL',
        'loguru': 'loguru',
        'addict': 'addict',
        'torchvision': 'torchvision',
        'modelscope': 'modelscope',
    }
    
    for package_name, import_name in required_packages.items():
        try:
            module = __import__(import_name)
            version = getattr(module, '__version__', 'unknown')
            print(f"   âœ… {package_name}: {version}")
        except ImportError:
            print(f"   âŒ {package_name}: æœªå®‰è£…")
            issues.append(f"è¯·å®‰è£… {package_name}")
    print()
    
    # 5. æ£€æŸ¥ flash-attn (å¯é€‰)
    print("ğŸ“Œ æ£€æŸ¥ flash-attn (å¯é€‰ä¼˜åŒ–):")
    try:
        import flash_attn
        print(f"   âœ… flash-attn å·²å®‰è£…: {flash_attn.__version__}")
    except ImportError:
        print("   âš ï¸  flash-attn æœªå®‰è£… (ä½¿ç”¨é»˜è®¤å®ç°)")
        warnings.append("flash-attn æœªå®‰è£…ï¼Œå°†ä½¿ç”¨é»˜è®¤å®ç° (æ€§èƒ½ç•¥ä½)")
    print()
    
    # 6. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    print("ğŸ“Œ æ£€æŸ¥æ¨¡å‹æ–‡ä»¶:")
    from pathlib import Path
    project_root = Path(__file__).parent.parent.parent
    model_path = project_root / 'models' / 'deepseek_ocr' / 'deepseek-ai' / 'DeepSeek-OCR'
    
    if model_path.exists():
        required_files = [
            'config.json',
            'tokenizer.json',
            'modeling_deepseekocr.py',
            'model-00001-of-000001.safetensors'
        ]
        
        all_exists = True
        for file_name in required_files:
            file_path = model_path / file_name
            if file_path.exists():
                print(f"   âœ… {file_name}")
            else:
                print(f"   âŒ {file_name} ç¼ºå¤±")
                all_exists = False
        
        if not all_exists:
            issues.append("æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´ï¼Œå°†åœ¨é¦–æ¬¡è¿è¡Œæ—¶è‡ªåŠ¨ä¸‹è½½")
    else:
        print("   âš ï¸  æ¨¡å‹æœªä¸‹è½½")
        warnings.append("æ¨¡å‹å°†åœ¨é¦–æ¬¡è¿è¡Œæ—¶è‡ªåŠ¨ä¸‹è½½ (çº¦ 10GB)")
    print()
    
    # æ€»ç»“
    print("=" * 80)
    print("ğŸ“Š æ£€æŸ¥ç»“æœ:")
    print("=" * 80)
    
    if not issues and not warnings:
        print("âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡! æ‰€æœ‰è¦æ±‚éƒ½å·²æ»¡è¶³ã€‚")
        print()
        print("ğŸš€ æ‚¨å¯ä»¥å¼€å§‹ä½¿ç”¨ DeepSeek OCR äº†!")
        print()
        print("   æµ‹è¯•å‘½ä»¤:")
        print("   cd backend/deepseek_ocr")
        print("   python test_basic.py")
        return True
    
    if warnings:
        print()
        print("âš ï¸  è­¦å‘Š:")
        for i, warning in enumerate(warnings, 1):
            print(f"   {i}. {warning}")
    
    if issues:
        print()
        print("âŒ å‘ç°é—®é¢˜:")
        for i, issue in enumerate(issues, 1):
            print(f"   {i}. {issue}")
        print()
        print("â— è¯·è§£å†³ä¸Šè¿°é—®é¢˜åå†ä½¿ç”¨ DeepSeek OCR")
        print()
        print("ğŸ“– è¯¦ç»†è¯´æ˜: backend/deepseek_ocr/GPU_REQUIREMENT.md")
        return False
    
    return True

if __name__ == '__main__':
    success = check_environment()
    sys.exit(0 if success else 1)

