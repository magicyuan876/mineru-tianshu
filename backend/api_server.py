"""
MinerU Tianshu - API Server
å¤©æ¢ API æœåŠ¡å™¨

ä¼ä¸šçº§ AI æ•°æ®é¢„å¤„ç†å¹³å°
æ”¯æŒæ–‡æ¡£ã€å›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®å¤„ç†
æä¾› RESTful API æ¥å£ç”¨äºä»»åŠ¡æäº¤ã€æŸ¥è¯¢å’Œç®¡ç†
ä¼ä¸šçº§è®¤è¯æˆæƒ: JWT Token + API Key + SSO
"""

from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Query, Depends
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pathlib import Path
from loguru import logger
import uvicorn
from typing import Optional
from datetime import datetime
import os
import re
import uuid
from minio import Minio

from task_db import TaskDB

# å¯¼å…¥è®¤è¯æ¨¡å—
from auth import (
    User,
    Permission,
    get_current_active_user,
    require_permission,
)
from auth.routes import router as auth_router
from auth.auth_db import AuthDB

# åˆå§‹åŒ– FastAPI åº”ç”¨
app = FastAPI(
    title="MinerU Tianshu API",
    description="å¤©æ¢ - ä¼ä¸šçº§ AI æ•°æ®é¢„å¤„ç†å¹³å° | æ”¯æŒæ–‡æ¡£ã€å›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®å¤„ç† | ä¼ä¸šçº§è®¤è¯æˆæƒ",
    version="2.0.0",
)

# æ·»åŠ  CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–æ•°æ®åº“
db = TaskDB()
auth_db = AuthDB()

# æ³¨å†Œè®¤è¯è·¯ç”±
app.include_router(auth_router)

# é…ç½®è¾“å‡ºç›®å½•ï¼ˆä½¿ç”¨å…±äº«ç›®å½•ï¼ŒDocker ç¯å¢ƒå¯è®¿é—®ï¼‰
OUTPUT_DIR = Path(os.getenv("OUTPUT_PATH", "/app/output"))
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# MinIO é…ç½®
MINIO_CONFIG = {
    "endpoint": os.getenv("MINIO_ENDPOINT", ""),
    "access_key": os.getenv("MINIO_ACCESS_KEY", ""),
    "secret_key": os.getenv("MINIO_SECRET_KEY", ""),
    "secure": True,
    "bucket_name": os.getenv("MINIO_BUCKET", ""),
}


def get_minio_client():
    """è·å–MinIOå®¢æˆ·ç«¯å®ä¾‹"""
    return Minio(
        MINIO_CONFIG["endpoint"],
        access_key=MINIO_CONFIG["access_key"],
        secret_key=MINIO_CONFIG["secret_key"],
        secure=MINIO_CONFIG["secure"],
    )


def process_markdown_images(md_content: str, image_dir: Path, upload_images: bool = False):
    """
    å¤„ç† Markdown ä¸­çš„å›¾ç‰‡å¼•ç”¨

    Args:
        md_content: Markdown å†…å®¹
        image_dir: å›¾ç‰‡æ‰€åœ¨ç›®å½•
        upload_images: æ˜¯å¦ä¸Šä¼ å›¾ç‰‡åˆ° MinIO å¹¶æ›¿æ¢é“¾æ¥

    Returns:
        å¤„ç†åçš„ Markdown å†…å®¹
    """
    if not upload_images:
        return md_content

    try:
        minio_client = get_minio_client()
        bucket_name = MINIO_CONFIG["bucket_name"]
        minio_endpoint = MINIO_CONFIG["endpoint"]

        # æŸ¥æ‰¾æ‰€æœ‰ markdown æ ¼å¼çš„å›¾ç‰‡
        img_pattern = r"!\[([^\]]*)\]\(([^)]+)\)"

        def replace_image(match):
            alt_text = match.group(1)
            image_path = match.group(2)

            # æ„å»ºå®Œæ•´çš„æœ¬åœ°å›¾ç‰‡è·¯å¾„
            full_image_path = image_dir / Path(image_path).name

            if full_image_path.exists():
                # è·å–æ–‡ä»¶åç¼€
                file_extension = full_image_path.suffix
                # ç”Ÿæˆ UUID ä½œä¸ºæ–°æ–‡ä»¶å
                new_filename = f"{uuid.uuid4()}{file_extension}"

                try:
                    # ä¸Šä¼ åˆ° MinIO
                    object_name = f"images/{new_filename}"
                    minio_client.fput_object(bucket_name, object_name, str(full_image_path))

                    # ç”Ÿæˆ MinIO è®¿é—® URL
                    scheme = "https" if MINIO_CONFIG["secure"] else "http"
                    minio_url = f"{scheme}://{minio_endpoint}/{bucket_name}/{object_name}"

                    # è¿”å› HTML æ ¼å¼çš„ img æ ‡ç­¾
                    return f'<img src="{minio_url}" alt="{alt_text}">'
                except Exception as e:
                    logger.error(f"Failed to upload image to MinIO: {e}")
                    return match.group(0)  # ä¸Šä¼ å¤±è´¥ï¼Œä¿æŒåŸæ ·

            return match.group(0)

        # æ›¿æ¢æ‰€æœ‰å›¾ç‰‡å¼•ç”¨
        new_content = re.sub(img_pattern, replace_image, md_content)
        return new_content

    except Exception as e:
        logger.error(f"Error processing markdown images: {e}")
        return md_content  # å‡ºé”™æ—¶è¿”å›åŸå†…å®¹


@app.get("/")
async def root():
    """APIæ ¹è·¯å¾„"""
    return {
        "service": "MinerU Tianshu",
        "version": "1.0.0",
        "description": "å¤©æ¢ - ä¼ä¸šçº§ AI æ•°æ®é¢„å¤„ç†å¹³å°",
        "features": "æ–‡æ¡£ã€å›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®å¤„ç†",
        "docs": "/docs",
    }


@app.post("/api/v1/tasks/submit")
async def submit_task(
    file: UploadFile = File(..., description="æ–‡ä»¶: PDF/å›¾ç‰‡/Office/HTML/éŸ³é¢‘/è§†é¢‘ç­‰å¤šç§æ ¼å¼"),
    backend: str = Form(
        "auto",
        description="å¤„ç†åç«¯: auto (è‡ªåŠ¨é€‰æ‹©) | pipeline/deepseek-ocr/paddleocr-vl (æ–‡æ¡£) | sensevoice (éŸ³é¢‘) | video (è§†é¢‘) | fasta/genbank (ä¸“ä¸šæ ¼å¼)",
    ),
    lang: str = Form("auto", description="è¯­è¨€: auto/ch/en/korean/japanç­‰"),
    method: str = Form("auto", description="è§£ææ–¹æ³•: auto/txt/ocr"),
    formula_enable: bool = Form(True, description="æ˜¯å¦å¯ç”¨å…¬å¼è¯†åˆ«"),
    table_enable: bool = Form(True, description="æ˜¯å¦å¯ç”¨è¡¨æ ¼è¯†åˆ«"),
    priority: int = Form(0, description="ä¼˜å…ˆçº§ï¼Œæ•°å­—è¶Šå¤§è¶Šä¼˜å…ˆ"),
    # DeepSeek OCR ä¸“ç”¨å‚æ•°
    deepseek_resolution: str = Form("base", description="DeepSeek OCR åˆ†è¾¨ç‡: tiny/small/base/large/dynamic"),
    deepseek_prompt_type: str = Form("document", description="DeepSeek OCR æç¤ºè¯ç±»å‹: document/image/free/figure"),
    # è§†é¢‘å¤„ç†ä¸“ç”¨å‚æ•°
    keep_audio: bool = Form(False, description="è§†é¢‘å¤„ç†æ—¶æ˜¯å¦ä¿ç•™æå–çš„éŸ³é¢‘æ–‡ä»¶"),
    enable_keyframe_ocr: bool = Form(False, description="æ˜¯å¦å¯ç”¨è§†é¢‘å…³é”®å¸§OCRè¯†åˆ«ï¼ˆå®éªŒæ€§åŠŸèƒ½ï¼‰"),
    ocr_backend: str = Form("paddleocr-vl", description="å…³é”®å¸§OCRå¼•æ“: paddleocr-vl/deepseek-ocr"),
    keep_keyframes: bool = Form(False, description="æ˜¯å¦ä¿ç•™æå–çš„å…³é”®å¸§å›¾åƒ"),
    # æ°´å°å»é™¤ä¸“ç”¨å‚æ•°
    remove_watermark: bool = Form(False, description="æ˜¯å¦å¯ç”¨æ°´å°å»é™¤ï¼ˆæ”¯æŒ PDF/å›¾ç‰‡ï¼‰"),
    watermark_conf_threshold: float = Form(0.35, description="æ°´å°æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆ0.0-1.0ï¼Œæ¨è 0.35ï¼‰"),
    watermark_dilation: int = Form(10, description="æ°´å°æ©ç è†¨èƒ€å¤§å°ï¼ˆåƒç´ ï¼Œæ¨è 10ï¼‰"),
    # è®¤è¯ä¾èµ–
    current_user: User = Depends(require_permission(Permission.TASK_SUBMIT)),
):
    """
    æäº¤æ–‡æ¡£è§£æä»»åŠ¡

    éœ€è¦è®¤è¯å’Œ TASK_SUBMIT æƒé™ã€‚
    ç«‹å³è¿”å› task_idï¼Œä»»åŠ¡åœ¨åå°å¼‚æ­¥å¤„ç†ã€‚
    """
    try:
        # åˆ›å»ºå…±äº«çš„ä¸Šä¼ ç›®å½•ï¼ˆBackend å’Œ Worker éƒ½èƒ½è®¿é—®ï¼‰
        upload_dir = Path("/app/uploads")
        upload_dir.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶åï¼ˆé¿å…å†²çªï¼‰
        unique_filename = f"{uuid.uuid4().hex}_{file.filename}"
        temp_file_path = upload_dir / unique_filename

        # æµå¼å†™å…¥æ–‡ä»¶åˆ°ç£ç›˜ï¼Œé¿å…é«˜å†…å­˜ä½¿ç”¨
        with open(temp_file_path, "wb") as temp_file:
            while True:
                chunk = await file.read(1 << 23)  # 8MB chunks
                if not chunk:
                    break
                temp_file.write(chunk)

        # åˆ›å»ºä»»åŠ¡ (å…³è”ç”¨æˆ·)
        task_id = db.create_task(
            file_name=file.filename,
            file_path=str(temp_file_path),
            backend=backend,
            options={
                "lang": lang,
                "method": method,
                "formula_enable": formula_enable,
                "table_enable": table_enable,
                # DeepSeek OCR å‚æ•°
                "deepseek_resolution": deepseek_resolution,
                "deepseek_prompt_type": deepseek_prompt_type,
                # è§†é¢‘å¤„ç†å‚æ•°
                "keep_audio": keep_audio,
                "enable_keyframe_ocr": enable_keyframe_ocr,
                "ocr_backend": ocr_backend,
                "keep_keyframes": keep_keyframes,
                # æ°´å°å»é™¤å‚æ•°
                "remove_watermark": remove_watermark,
                "watermark_conf_threshold": watermark_conf_threshold,
                "watermark_dilation": watermark_dilation,
            },
            priority=priority,
            user_id=current_user.user_id,  # å…³è”ç”¨æˆ·
        )

        logger.info(f"âœ… Task submitted: {task_id} - {file.filename}")
        logger.info(f"   User: {current_user.username} ({current_user.role.value})")
        logger.info(f"   Backend: {backend}")
        logger.info(f"   Priority: {priority}")
        if backend == "deepseek-ocr":
            logger.info(f"   DeepSeek Resolution: {deepseek_resolution}")
            logger.info(f"   DeepSeek Prompt Type: {deepseek_prompt_type}")

        return {
            "success": True,
            "task_id": task_id,
            "status": "pending",
            "message": "Task submitted successfully",
            "file_name": file.filename,
            "user_id": current_user.user_id,
            "created_at": datetime.now().isoformat(),
        }

    except Exception as e:
        logger.error(f"âŒ Failed to submit task: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/tasks/{task_id}")
async def get_task_status(
    task_id: str,
    upload_images: bool = Query(False, description="æ˜¯å¦ä¸Šä¼ å›¾ç‰‡åˆ°MinIOå¹¶æ›¿æ¢é“¾æ¥ï¼ˆä»…å½“ä»»åŠ¡å®Œæˆæ—¶æœ‰æ•ˆï¼‰"),
    format: str = Query("markdown", description="è¿”å›æ ¼å¼: markdown(é»˜è®¤)/json/both"),
    current_user: User = Depends(get_current_active_user),
):
    """
    æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å’Œè¯¦æƒ…

    éœ€è¦è®¤è¯ã€‚ç”¨æˆ·åªèƒ½æŸ¥çœ‹è‡ªå·±çš„ä»»åŠ¡ï¼Œç®¡ç†å‘˜å¯ä»¥æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡ã€‚
    å½“ä»»åŠ¡å®Œæˆæ—¶ï¼Œä¼šè‡ªåŠ¨è¿”å›è§£æåçš„å†…å®¹ï¼ˆdata å­—æ®µï¼‰
    - format=markdown: åªè¿”å› Markdown å†…å®¹ï¼ˆé»˜è®¤ï¼‰
    - format=json: åªè¿”å› JSON ç»“æ„åŒ–æ•°æ®ï¼ˆMinerU å’Œ PaddleOCR-VL æ”¯æŒï¼‰
    - format=both: åŒæ—¶è¿”å› Markdown å’Œ JSON
    å¯é€‰æ‹©æ˜¯å¦ä¸Šä¼ å›¾ç‰‡åˆ° MinIO å¹¶æ›¿æ¢ä¸º URL
    """
    task = db.get_task(task_id)

    if not task:
        raise HTTPException(status_code=404, detail="Task not found")

    # æƒé™æ£€æŸ¥: ç”¨æˆ·åªèƒ½æŸ¥çœ‹è‡ªå·±çš„ä»»åŠ¡ï¼Œç®¡ç†å‘˜/ç»ç†å¯ä»¥æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡
    if not current_user.has_permission(Permission.TASK_VIEW_ALL):
        if task.get("user_id") != current_user.user_id:
            raise HTTPException(status_code=403, detail="Permission denied: You can only view your own tasks")

    response = {
        "success": True,
        "task_id": task_id,
        "status": task["status"],
        "file_name": task["file_name"],
        "backend": task["backend"],
        "priority": task["priority"],
        "error_message": task["error_message"],
        "created_at": task["created_at"],
        "started_at": task["started_at"],
        "completed_at": task["completed_at"],
        "worker_id": task["worker_id"],
        "retry_count": task["retry_count"],
        "user_id": task.get("user_id"),
    }
    logger.info(f"âœ… Task status: {task['status']} - (result_path: {task['result_path']})")

    # å¦‚æœä»»åŠ¡å·²å®Œæˆï¼Œå°è¯•è¿”å›è§£æå†…å®¹
    if task["status"] == "completed":
        if not task["result_path"]:
            # ç»“æœæ–‡ä»¶å·²è¢«æ¸…ç†
            response["data"] = None
            response["message"] = "Task completed but result files have been cleaned up (older than retention period)"
            return response

        result_dir = Path(task["result_path"])
        logger.info(f"ğŸ“‚ Checking result directory: {result_dir}")

        if result_dir.exists():
            logger.info("âœ… Result directory exists")
            # é€’å½’æŸ¥æ‰¾ Markdown æ–‡ä»¶ï¼ˆMinerU è¾“å‡ºç»“æ„ï¼štask_id/filename/auto/*.mdï¼‰
            md_files = list(result_dir.rglob("*.md"))
            # é€’å½’æŸ¥æ‰¾ JSON æ–‡ä»¶
            # MinerU è¾“å‡ºæ ¼å¼: {filename}_content_list.json (ä¸»è¦çš„ç»“æ„åŒ–å†…å®¹)
            # ä¹Ÿæ”¯æŒå…¶ä»–å¼•æ“çš„: content.json, result.json
            json_files = [
                f
                for f in result_dir.rglob("*.json")
                if not f.parent.name.startswith("page_")
                and (f.name in ["content.json", "result.json"] or "_content_list.json" in f.name)
            ]
            logger.info(f"ğŸ“„ Found {len(md_files)} markdown files and {len(json_files)} json files")

            if md_files:
                try:
                    # åˆå§‹åŒ– data å­—æ®µ
                    response["data"] = {}

                    # æ ‡è®° JSON æ˜¯å¦å¯ç”¨
                    response["data"]["json_available"] = len(json_files) > 0

                    # æ ¹æ® format å‚æ•°å†³å®šè¿”å›å†…å®¹
                    if format in ["markdown", "both"]:
                        # è¯»å– Markdown å†…å®¹
                        md_file = md_files[0]
                        logger.info(f"ğŸ“– Reading markdown file: {md_file}")
                        with open(md_file, "r", encoding="utf-8") as f:
                            md_content = f.read()

                        logger.info(f"âœ… Markdown content loaded, length: {len(md_content)} characters")

                        # æŸ¥æ‰¾å›¾ç‰‡ç›®å½•ï¼ˆåœ¨ markdown æ–‡ä»¶çš„åŒçº§ç›®å½•ä¸‹ï¼‰
                        image_dir = md_file.parent / "images"

                        # å¤„ç†å›¾ç‰‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
                        if upload_images and image_dir.exists():
                            logger.info(f"ğŸ–¼ï¸  Processing images for task {task_id}, upload_images={upload_images}")
                            md_content = process_markdown_images(md_content, image_dir, upload_images)

                        # æ·»åŠ  Markdown ç›¸å…³å­—æ®µ
                        response["data"]["markdown_file"] = md_file.name
                        response["data"]["content"] = md_content
                        response["data"]["images_uploaded"] = upload_images
                        response["data"]["has_images"] = image_dir.exists() if not upload_images else None

                    # å¦‚æœç”¨æˆ·è¯·æ±‚ JSON æ ¼å¼
                    if format in ["json", "both"] and json_files:
                        import json as json_lib

                        json_file = json_files[0]
                        logger.info(f"ğŸ“– Reading JSON file: {json_file}")
                        try:
                            with open(json_file, "r", encoding="utf-8") as f:
                                json_content = json_lib.load(f)
                            response["data"]["json_file"] = json_file.name
                            response["data"]["json_content"] = json_content
                            logger.info("âœ… JSON content loaded successfully")
                        except Exception as json_e:
                            logger.warning(f"âš ï¸  Failed to load JSON: {json_e}")
                    elif format == "json" and not json_files:
                        # ç”¨æˆ·è¯·æ±‚ JSON ä½†æ²¡æœ‰ JSON æ–‡ä»¶
                        logger.warning("âš ï¸  JSON format requested but no JSON file available")
                        response["data"]["message"] = "JSON format not available for this backend"

                    # å¦‚æœæ²¡æœ‰è¿”å›ä»»ä½•å†…å®¹ï¼Œæ·»åŠ æç¤º
                    if not response["data"]:
                        response["data"] = None
                        logger.warning(f"âš ï¸  No data returned for format: {format}")
                    else:
                        logger.info(f"âœ… Response data field added successfully (format={format})")

                except Exception as e:
                    logger.error(f"âŒ Failed to read content: {e}")
                    logger.exception(e)
                    # è¯»å–å¤±è´¥ä¸å½±å“çŠ¶æ€æŸ¥è¯¢ï¼Œåªæ˜¯ä¸è¿”å› data
                    response["data"] = None
            else:
                logger.warning(f"âš ï¸  No markdown files found in {result_dir}")
        else:
            logger.error(f"âŒ Result directory does not exist: {result_dir}")
    elif task["status"] == "completed":
        logger.warning("âš ï¸  Task completed but result_path is empty")
    else:
        logger.info(f"â„¹ï¸  Task status is {task['status']}, skipping content loading")

    return response


@app.delete("/api/v1/tasks/{task_id}")
async def cancel_task(task_id: str, current_user: User = Depends(get_current_active_user)):
    """
    å–æ¶ˆä»»åŠ¡ï¼ˆä»…é™ pending çŠ¶æ€ï¼‰

    éœ€è¦è®¤è¯ã€‚ç”¨æˆ·åªèƒ½å–æ¶ˆè‡ªå·±çš„ä»»åŠ¡ï¼Œç®¡ç†å‘˜å¯ä»¥å–æ¶ˆä»»ä½•ä»»åŠ¡ã€‚
    """
    task = db.get_task(task_id)

    if not task:
        raise HTTPException(status_code=404, detail="Task not found")

    # æƒé™æ£€æŸ¥: ç”¨æˆ·åªèƒ½å–æ¶ˆè‡ªå·±çš„ä»»åŠ¡ï¼Œç®¡ç†å‘˜å¯ä»¥å–æ¶ˆä»»ä½•ä»»åŠ¡
    if not current_user.has_permission(Permission.TASK_DELETE_ALL):
        if task.get("user_id") != current_user.user_id:
            raise HTTPException(status_code=403, detail="Permission denied: You can only cancel your own tasks")

    if task["status"] == "pending":
        db.update_task_status(task_id, "cancelled")

        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        file_path = Path(task["file_path"])
        if file_path.exists():
            file_path.unlink()

        logger.info(f"â¹ï¸  Task cancelled: {task_id} by user {current_user.username}")
        return {"success": True, "message": "Task cancelled successfully"}
    else:
        raise HTTPException(status_code=400, detail=f"Cannot cancel task in {task['status']} status")


@app.get("/api/v1/queue/stats")
async def get_queue_stats(current_user: User = Depends(require_permission(Permission.QUEUE_VIEW))):
    """
    è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯

    éœ€è¦è®¤è¯å’Œ QUEUE_VIEW æƒé™ã€‚
    """
    stats = db.get_queue_stats()

    return {
        "success": True,
        "stats": stats,
        "total": sum(stats.values()),
        "timestamp": datetime.now().isoformat(),
        "user": current_user.username,
    }


@app.get("/api/v1/queue/tasks")
async def list_tasks(
    status: Optional[str] = Query(None, description="ç­›é€‰çŠ¶æ€: pending/processing/completed/failed"),
    limit: int = Query(100, description="è¿”å›æ•°é‡é™åˆ¶", le=1000),
    current_user: User = Depends(get_current_active_user),
):
    """
    è·å–ä»»åŠ¡åˆ—è¡¨

    éœ€è¦è®¤è¯ã€‚æ™®é€šç”¨æˆ·åªèƒ½çœ‹åˆ°è‡ªå·±çš„ä»»åŠ¡ï¼Œç®¡ç†å‘˜/ç»ç†å¯ä»¥çœ‹åˆ°æ‰€æœ‰ä»»åŠ¡ã€‚
    """
    # æ£€æŸ¥ç”¨æˆ·æƒé™
    can_view_all = current_user.has_permission(Permission.TASK_VIEW_ALL)

    if can_view_all:
        # ç®¡ç†å‘˜/ç»ç†æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡
        if status:
            tasks = db.get_tasks_by_status(status, limit)
        else:
            with db.get_cursor() as cursor:
                cursor.execute(
                    """
                    SELECT * FROM tasks
                    ORDER BY created_at DESC
                    LIMIT ?
                """,
                    (limit,),
                )
                tasks = [dict(row) for row in cursor.fetchall()]
    else:
        # æ™®é€šç”¨æˆ·åªèƒ½çœ‹åˆ°è‡ªå·±çš„ä»»åŠ¡
        with db.get_cursor() as cursor:
            if status:
                cursor.execute(
                    """
                    SELECT * FROM tasks
                    WHERE user_id = ? AND status = ?
                    ORDER BY created_at DESC
                    LIMIT ?
                """,
                    (current_user.user_id, status, limit),
                )
            else:
                cursor.execute(
                    """
                    SELECT * FROM tasks
                    WHERE user_id = ?
                    ORDER BY created_at DESC
                    LIMIT ?
                """,
                    (current_user.user_id, limit),
                )
            tasks = [dict(row) for row in cursor.fetchall()]

    return {"success": True, "count": len(tasks), "tasks": tasks, "can_view_all": can_view_all}


@app.post("/api/v1/admin/cleanup")
async def cleanup_old_tasks(
    days: int = Query(7, description="æ¸…ç†Nå¤©å‰çš„ä»»åŠ¡"),
    current_user: User = Depends(require_permission(Permission.QUEUE_MANAGE)),
):
    """
    æ¸…ç†æ—§ä»»åŠ¡è®°å½•ï¼ˆç®¡ç†æ¥å£ï¼‰

    éœ€è¦ç®¡ç†å‘˜æƒé™ã€‚
    """
    deleted_count = db.cleanup_old_tasks(days)

    logger.info(f"ğŸ§¹ Cleaned up {deleted_count} old tasks by {current_user.username}")

    return {"success": True, "deleted_count": deleted_count, "message": f"Cleaned up tasks older than {days} days"}


@app.post("/api/v1/admin/reset-stale")
async def reset_stale_tasks(
    timeout_minutes: int = Query(60, description="è¶…æ—¶æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰"),
    current_user: User = Depends(require_permission(Permission.QUEUE_MANAGE)),
):
    """
    é‡ç½®è¶…æ—¶çš„ processing ä»»åŠ¡ï¼ˆç®¡ç†æ¥å£ï¼‰

    éœ€è¦ç®¡ç†å‘˜æƒé™ã€‚
    """
    reset_count = db.reset_stale_tasks(timeout_minutes)

    logger.info(f"ğŸ”„ Reset {reset_count} stale tasks by {current_user.username}")

    return {
        "success": True,
        "reset_count": reset_count,
        "message": f"Reset tasks processing for more than {timeout_minutes} minutes",
    }


@app.get("/api/v1/engines")
async def list_engines():
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å¤„ç†å¼•æ“

    æ— éœ€è®¤è¯ã€‚è¿”å›ç³»ç»Ÿä¸­æ‰€æœ‰å¯ç”¨çš„å¤„ç†å¼•æ“ä¿¡æ¯ã€‚
    """
    engines = {
        "document": [
            {
                "name": "pipeline",
                "display_name": "MinerU Pipeline",
                "description": "é»˜è®¤çš„ PDF/å›¾ç‰‡è§£æå¼•æ“ï¼Œæ”¯æŒå…¬å¼ã€è¡¨æ ¼ç­‰å¤æ‚ç»“æ„",
                "supported_formats": [".pdf", ".png", ".jpg", ".jpeg"],
            },
        ],
        "ocr": [],
        "audio": [],
        "video": [],
        "format": [],
        "office": [
            {
                "name": "markitdown",
                "display_name": "MarkItDown",
                "description": "Office æ–‡æ¡£å’Œæ–‡æœ¬æ–‡ä»¶è½¬æ¢å¼•æ“",
                "supported_formats": [".docx", ".xlsx", ".pptx", ".doc", ".xls", ".ppt", ".html", ".txt", ".csv"],
            },
        ],
    }

    # åŠ¨æ€æ£€æµ‹å¯ç”¨å¼•æ“
    import importlib.util

    if importlib.util.find_spec("deepseek_ocr") is not None:
        engines["ocr"].append(
            {
                "name": "deepseek_ocr",
                "display_name": "DeepSeek OCR",
                "description": "é«˜ç²¾åº¦ OCR å¼•æ“ï¼Œæ”¯æŒå¤šç§åˆ†è¾¨ç‡å’Œæç¤ºè¯æ¨¡å¼",
                "supported_formats": [".pdf", ".png", ".jpg", ".jpeg"],
            }
        )

    if importlib.util.find_spec("paddleocr_vl") is not None:
        engines["ocr"].append(
            {
                "name": "paddleocr_vl",
                "display_name": "PaddleOCR-VL",
                "description": "PaddlePaddle è§†è§‰è¯­è¨€ OCR å¼•æ“",
                "supported_formats": [".pdf", ".png", ".jpg", ".jpeg"],
            }
        )

    if importlib.util.find_spec("audio_engines") is not None:
        engines["audio"].append(
            {
                "name": "sensevoice",
                "display_name": "SenseVoice",
                "description": "è¯­éŸ³è¯†åˆ«å¼•æ“ï¼Œæ”¯æŒå¤šè¯­è¨€è‡ªåŠ¨æ£€æµ‹",
                "supported_formats": [".wav", ".mp3", ".flac", ".m4a", ".ogg"],
            }
        )

    if importlib.util.find_spec("video_engines") is not None:
        engines["video"].append(
            {
                "name": "video",
                "display_name": "Video Processing",
                "description": "è§†é¢‘å¤„ç†å¼•æ“ï¼Œæ”¯æŒå…³é”®å¸§æå–å’ŒéŸ³é¢‘è½¬å½•",
                "supported_formats": [".mp4", ".avi", ".mkv", ".mov", ".flv", ".wmv"],
            }
        )

    # ä¸“ä¸šæ ¼å¼å¼•æ“
    try:
        from format_engines import FormatEngineRegistry

        for engine_info in FormatEngineRegistry.list_engines():
            engines["format"].append(
                {
                    "name": engine_info["name"],
                    "display_name": engine_info["name"].upper(),
                    "description": engine_info["description"],
                    "supported_formats": engine_info["extensions"],
                }
            )
    except ImportError:
        pass

    return {
        "success": True,
        "engines": engines,
        "timestamp": datetime.now().isoformat(),
    }


@app.get("/api/v1/health")
async def health_check():
    """
    å¥åº·æ£€æŸ¥æ¥å£
    """
    try:
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        stats = db.get_queue_stats()

        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "database": "connected",
            "queue_stats": stats,
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return JSONResponse(status_code=503, content={"status": "unhealthy", "error": str(e)})


if __name__ == "__main__":
    # ä»ç¯å¢ƒå˜é‡è¯»å–ç«¯å£ï¼Œé»˜è®¤ä¸º8000
    api_port = int(os.getenv("API_PORT", "8000"))

    logger.info("ğŸš€ Starting MinerU Tianshu API Server...")
    logger.info(f"ğŸ“– API Documentation: http://localhost:{api_port}/docs")

    uvicorn.run(app, host="0.0.0.0", port=api_port, log_level="info")
